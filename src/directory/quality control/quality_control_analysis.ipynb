{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sandbox_mturk_manual.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU2jzJSQvAdI"
      },
      "source": [
        "Maya Patel\n",
        "\n",
        "NETS 213 Final Project\n",
        "\n",
        "This script will analyze the labels given by the sandbox workers (experts), the Turkers (the crowd), and ourselves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3ezNA3wvZxM"
      },
      "source": [
        "import pandas as pd\n",
        "import csv"
      ],
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQoMi-lmye_H"
      },
      "source": [
        "# import csv files\n",
        "sandbox_df = pd.read_csv(\"sandbox_results_final.csv\")\n",
        "turkers_df = pd.read_csv(\"mturk_labels.csv\")\n",
        "ourselves_df = pd.read_csv(\"sandbox_manual_url_labels.csv\")"
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zo078g90PqC"
      },
      "source": [
        "# grab relevant columns\n",
        "def columns(df):\n",
        "  return df[['Input.url', 'Answer.asian_hate_crime', 'Answer.reference_hate']]"
      ],
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-J7Zsbbe83x"
      },
      "source": [
        "sandbox_df = columns(sandbox_df)\n",
        "turkers_df = columns(turkers_df)\n",
        "ourselves_df = columns(ourselves_df)\n",
        "ourselves_df['Answer.asian_hate_crime'] = ourselves_df['Answer.asian_hate_crime'].apply(lambda x: True if x == 'TRUE' else False)"
      ],
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9I36BIbi6Fp"
      },
      "source": [
        "# given control and experimental data, how many times did the experimental data agree with control?\n",
        "def agree(control, experimental):\n",
        "  total_urls = len(control)\n",
        "  agree_only_hate_crime = 0\n",
        "  agree_only_ref_hate = 0\n",
        "  agree_both = 0\n",
        "  no_agree = 0\n",
        "  for i in range(0, len(control)):\n",
        "    # find ith url in control, extract answers\n",
        "    curr_url = control.at[i, 'Input.url']\n",
        "    is_hate_crime = control.at[i, 'Answer.asian_hate_crime'].item()\n",
        "    is_ref_hate = control.at[i, 'Answer.reference_hate'].item()\n",
        "\n",
        "    # extract answers from experimental\n",
        "    exp_row = experimental.loc[experimental['Input.url'] == curr_url]\n",
        "\n",
        "    exp_hate_crime_ans = False\n",
        "    exp_ref_hate_ans = False\n",
        "    \n",
        "    if (len(exp_row['Answer.asian_hate_crime'].tolist()) == 0 or len(exp_row['Answer.reference_hate'].tolist()) == 0):\n",
        "      total_urls = total_urls - 1\n",
        "      continue\n",
        "    \n",
        "    exp_hate_crime_ans = exp_row['Answer.asian_hate_crime'].tolist()[0]\n",
        "    exp_ref_hate_ans = exp_row['Answer.reference_hate'].tolist()[0]\n",
        "\n",
        "    agree_hc = is_hate_crime == exp_hate_crime_ans\n",
        "    agree_rf = is_ref_hate == exp_ref_hate_ans\n",
        "    agree_only_hc = agree_hc and (not(agree_rf))\n",
        "    agree_only_rf = (not(agree_hc)) and agree_rf\n",
        "    agree_both_2 = agree_hc and agree_rf\n",
        "\n",
        "    if (agree_only_hc):\n",
        "      agree_only_hate_crime = agree_only_hate_crime + 1\n",
        "    elif (agree_only_rf):\n",
        "      agree_only_ref_hate = agree_only_ref_hate + 1\n",
        "    elif (agree_both_2):\n",
        "      agree_both = agree_both + 1\n",
        "    else:\n",
        "      no_agree = no_agree + 1\n",
        "  \n",
        "  agree_only_hate_crime = (agree_only_hate_crime / total_urls) * 100\n",
        "  agree_only_ref_hate = (agree_only_ref_hate / total_urls) * 100\n",
        "  agree_both = (agree_both / total_urls) * 100\n",
        "  no_agree = (no_agree / total_urls) * 100\n",
        "  data = {'Outcome': ['Agreed Only on Hate Crime', 'Agreed Only on References Hate', 'Agreed on Both', 'Did not Agree'], 'Percent Occurred': [agree_only_hate_crime, agree_only_ref_hate, agree_both, no_agree]}\n",
        "  return pd.DataFrame(data, columns=['Outcome', 'Percent Occurred'])"
      ],
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O34P37GDQtaz"
      },
      "source": [
        "We can use the code above to see how much two sets of people were in agreement or not.  Let's compare the expert labels (from Sandbox) with the crowd labels (from MTurk)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "iR3DciG2UWTh",
        "outputId": "c39aa752-74c8-4981-d045-cd1a22e51824"
      },
      "source": [
        "agree(turkers_df, sandbox_df)"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Outcome</th>\n",
              "      <th>Percent Occurred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Agreed Only on Hate Crime</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Agreed Only on References Hate</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Agreed on Both</td>\n",
              "      <td>74.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Did not Agree</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Outcome  Percent Occurred\n",
              "0       Agreed Only on Hate Crime              10.0\n",
              "1  Agreed Only on References Hate               7.0\n",
              "2                  Agreed on Both              74.0\n",
              "3                   Did not Agree               9.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvOy-MYpUaw7"
      },
      "source": [
        "Assuming that the expert labels are 100% accurate, we see that the Turkers were correct with both questions 75% of the time.  13.64% of the time, they were wrong with both questions. 2.27% of the time, they only correctly identified if the article described a hate crime and 9.09% of the time, they only correctly identifed if the article references hate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47WUnFhGVCLZ"
      },
      "source": [
        "Now, let's compare the labels that we completed with the crowd labels (from MTurk)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "cOjt6H8mVKXy",
        "outputId": "3b8c8600-8ecb-48ce-954c-4b854db743e1"
      },
      "source": [
        "agree(ourselves_df, turkers_df)"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Outcome</th>\n",
              "      <th>Percent Occurred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Agreed Only on Hate Crime</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Agreed Only on References Hate</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Agreed on Both</td>\n",
              "      <td>72.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Did not Agree</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Outcome  Percent Occurred\n",
              "0       Agreed Only on Hate Crime              13.0\n",
              "1  Agreed Only on References Hate              10.0\n",
              "2                  Agreed on Both              72.0\n",
              "3                   Did not Agree               5.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL9cNbVlVS3j"
      },
      "source": [
        "Assuming that our opinions are 100% accurate, we see that the Turkers were much less accurate.  They only answered both questions correctly 56.81% of the time and answered both questions wrong 9.09% of the time.  They only answered the hate crime question correcltly 11.36% of the time and only answered the references hate question 22.73% of the time.  This gives us a better idea of how accurate the Turkers really are."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ywgb4N9VmxI"
      },
      "source": [
        "Now, let's compare the labels that we completed with the expert labels (from Sandbox)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "cOUXzkrlVsDT",
        "outputId": "f873c8e5-37ff-466f-af24-2e77d8442898"
      },
      "source": [
        "agree(ourselves_df, sandbox_df)"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Outcome</th>\n",
              "      <th>Percent Occurred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Agreed Only on Hate Crime</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Agreed Only on References Hate</td>\n",
              "      <td>18.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Agreed on Both</td>\n",
              "      <td>70.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Did not Agree</td>\n",
              "      <td>1.666667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Outcome  Percent Occurred\n",
              "0       Agreed Only on Hate Crime         10.000000\n",
              "1  Agreed Only on References Hate         18.333333\n",
              "2                  Agreed on Both         70.000000\n",
              "3                   Did not Agree          1.666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsNzI98ZV1Sp"
      },
      "source": [
        "Assuming that our opinions are 100% accurate, we see that the experts answered both questions correctly 70% of the time and were totally wrong only 1.67% of the time.  However, they only got the hate crime question correct 10% of the time and the references hate question 18.33% of the time.  This suggests that our expert dataset could be interpreted as flawed depending on which opinion (ours or the experts) is considered 100% correct."
      ]
    }
  ]
}